---
title: "Class 8: Unsupervised Learning Mini-Project"
author: "Nathaniel Nono (PID: A16782656)"
format: pdf
---

# Introductionary Lecture

## Scaling

```{r}
data(mtcars)
head(mtcars)
```

```{r}
colMeans(mtcars)
```

```{r}
apply(mtcars, 2, sd)
```

It is important to scale your data: This will cause all of the data to be in more appropritate units

```{r}
x <- scale(mtcars)
head(x)
```

```{r}
round(colMeans(x),2)
```

# In-class Lab Section

## Explanatory Data Analysis

Preparing the data

```{r}
# Save your input data file into your Project directory
fna.data <- "WisconsinCancer.csv"

# Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv(fna.data, row.names=1)
```

```{r}
head(wisc.df)
```

```{r}
colnames(wisc.df)
```

Remove this first `diagnosis` coulmn from the dataset as I don't want to pass this PCA etc. It is essentially the experet "answer" that we wioll compare our analysis results to

```{r}
# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]
head(wisc.data)
colnames(wisc.data)
```

Takes a subset of the data of the first column

```{r}
diagnosis <- wisc.df$diagnosis
diagnosis
```

### **Q1**. How many observations are in this dataset?

```{r}
nrow(wisc.df)
```

**There are 569 observations in this data set**(

### **Q2**. How many of the observations have a malignant diagnosis?

```{r}
table(diagnosis)
```

**There are 212 observations of the malignant diagnosis**

### **Q3**. How many variables/features in the data are suffixed with `_mean`?

```{r}
col_mean <- grep('_mean', colnames(wisc.df))
length(col_mean)
```

**There are 10 variables/features in the data that are suffixed with `_mean`**

## Principal Component Analysis

Performing PCA on the `wisc.df`

- Always want to scale

- Different means and SDs so we want to treat the entire data set equally

```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp( wisc.data, scale=T )
summary(wisc.pr)
```


See what is in our PCA result object -> List of 5 "things"

```{r}
attributes(wisc.pr)
```

### **Q4**. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

**44% of the variance is captured in PC1**

### **Q5**. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

**You need 3 PCAs**

### **Q6**. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

**You need 7 PCAs**

### **Q7.** What stands out to you about this plot? Is it easy or difficult to understand? Why?

Should use the first 2 columns to make the highest percentage. 

```{r}
head(wisc.pr$x)

# Default = Take the first two columns
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=as.factor(diagnosis),
     xlab = "PC1", 
     ylab = "PC2")
```

**There is a stark difference in clustering between the red and black cells showing the diagnosis of the individual**

### **Q8.** Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=as.factor(diagnosis),
     xlab = "PC1", 
     ylab = "PC3")
```

**The cells are moving closer together and show less amount of clustering. But there are still levels of separation to allow for prediction**



### **Q9.** For the first principal component, what is the component of the loading vector (i.e.`wisc.pr$rotation[,1]`) for the feature`concave.points_mean`?

```{r}
wisc.pr$rotation['concave.points_mean', 1]
```

**-0.26085376 is the component of the loading vector**



### **Q10.** What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
y <- summary(wisc.pr)
y$importance[2,]
```

**You need 5 principle components**



## Hierarchical Clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

```{r}
data.dist <- dist(data.scaled)
```

```{r}
wisc.hclust <- hclust(data.dist, method='complete')
```


### **Q11.** Using the `plot()` and `abline()` functions, what is the height at which the clustering model has 4 clusters?


```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

**After scaling the data the height that has 4 clusters is 19**

### **Q12.** Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, h=19)
```


Our PCA results were in `wisc.pr$x`

```{r}
# Distance matrix from PCA result
d <- dist(wisc.pr$x[,1:3])

# 
hc <- hclust(d, method='ward.D2')
plot(hc)
```

Cut tree into two groups/clusters
```{r}
grps2 <- cutree(hc, k=2)
plot(wisc.pr$x, col=grps2)
```


Cut tree into ten groups/clusters
```{r}
grps10 <- cutree(hc, k=10)
plot(wisc.pr$x, col=grps10)
```



Compare my clustering result (my `grps`) to the expert `diagnosis`

```{r}
table(diagnosis)
```

```{r}
table(grps2)
```


Cross table w/2 groups: 

```{r}
table(diagnosis, grps2)
```

**In all of cluster 1 there are 24 benign points and 179 malignant point. In all of cluster 2 there are 333 benign points and 33 malignant points.**


Cross table w/10 groups:

```{r}
table(diagnosis, grps10)
```
**It is really hard to tell the clusters of whether one is particularly benign or malignant. However this is helpful for solving false positives.**










